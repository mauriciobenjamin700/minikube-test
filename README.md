# Toler√¢ncia a Falhas e Monitoramento com Kubernetes + Prometheus

**Objetivo Geral**:

Implantar uma aplica√ß√£o distribu√≠da com Kubernetes em um ambiente local, aplicando t√©cnicas de toler√¢ncia a falhas, auto-recupera√ß√£o, escalonamento horizontal e monitoramento remoto, utilizando dois notebooks interligados.

## Descri√ß√£o da Implanta√ß√£o

- ‚úÖ Notebook A ‚Äì Cluster Kubernetes
  - Criar um cluster local com Minikube.
  - Implantar uma aplica√ß√£o com m√∫ltiplos pods, iniciando com duas r√©plicas.
  - **Aten√ß√£o**: a aplica√ß√£o n√£o pode ser reutilizada de atividades anteriores da disciplina.
  - Habilitar o mecanismo de auto-healing, garantindo que pods sejam recriados automaticamente em caso de falha.
  - Configurar o Horizontal Pod Autoscaler (HPA) com base no uso de CPU.
- ‚úÖ Notebook B ‚Äì Prometheus
  - Implantar o Prometheus para monitoramento remoto do cluster Kubernetes no Notebook A.
  - Exibir m√©tricas em tempo real, como:
  - N√∫mero de pods ativos
  - Uso de CPU
  - Estado dos pods (Running, Failed, Pending)
  - A√ß√µes disparadas pelo HPA

## Demonstra√ß√£o de Toler√¢ncia a Falhas

Antes de iniciar os testes, mostre que sua aplica√ß√£o est√° rodando normalmente com as duas r√©plicas previstas.

- 1.Dele√ß√£o Manual de Pod (Auto-Healing)
  - Delete manualmente um dos pods da aplica√ß√£o.
  - Observe como o controlador do Kubernetes detecta a falha e recria automaticamente um novo pod.
- üìå O que demonstrar:
  - A recria√ß√£o r√°pida de um novo pod ap√≥s a dele√ß√£o.
  - O status de ‚ÄúTerminating‚Äù do pod anterior e a entrada do novo em ‚ÄúRunning‚Äù.
  - A atualiza√ß√£o das m√©tricas no Prometheus (mudan√ßa no n√∫mero de pods ativos, novo identificador, tempo de rea√ß√£o).
- 2.Sobrecarga de CPU (Escalonamento Horizontal)
  - Gere uma carga de CPU artificial em um ou mais pods da aplica√ß√£o.
  - Observe como o HPA aumenta automaticamente o n√∫mero de r√©plicas para atender √† demanda.
- üìå O que demonstrar:
  - A eleva√ß√£o do consumo de CPU no Prometheus.
  - A cria√ß√£o de novos pods, respeitando o limite configurado no HPA.
  - O tempo de resposta entre o pico de CPU e o escalonamento autom√°tico.
  - A redu√ß√£o do n√∫mero de r√©plicas ap√≥s estabiliza√ß√£o (se aplic√°vel).

## Resultados

Primeiramente, vamos configurar o ambiente, onde recomendamos fortemente que siga a [documenta√ß√£o oficial](https://minikube.sigs.k8s.io/docs/start/?arch=%2Flinux%2Fx86-64%2Fstable%2Fdebian+package) com base em seu sistema operacional.

Usaremos Linux Ubuntu 24.04 LTS neste projeto

### Instalando Minikube

Usaremos o comando a baixo para instalar:

```bash
curl -LO https://storage.googleapis.com/minikube/releases/latest/minikube_latest_amd64.deb
sudo dpkg -i minikube_latest_amd64.deb

```

Use o comando `minikube start` para checar se o minikube esta funcionando corretamente.

O resultado esperado ser√° semelhante a este:

```bash
üòÑ  minikube v1.35.0 on Ubuntu 24.04
‚ú®  Automatically selected the docker driver. Other choices: none, ssh
üìå  Using Docker driver with root privileges
üëç  Starting "minikube" primary control-plane node in "minikube" cluster
üöú  Pulling base image v0.0.46 ...
```

Para interagir com o minikube, iremos instalar o kubectl (Linha de Comandos do Kubernets) seguindo a [documenta√ß√£o oficial](https://kubernetes.io/docs/tasks/tools/)

Comandos usados

```bash
curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl.sha256"
```

Use este comando para testar se o kubectl foi baixado com sucesso:

```bash
echo "$(cat kubectl.sha256)  kubectl" | sha256sum --check
```

Resultado esperado:

```bash
kubectl: OK
```

Agora o instale usando:

```bash
sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl
```

Use este comando para testar se a instala√ß√£o aconteceu corretamente:

```bash
kubectl version --client
```

Resultado esperado:

```bash
Client Version: v1.32.3
Kustomize Version: v5.5.0
```

### Criar um cluster local com Minikube

Inicialmente vamos criar duas replicas da nossa aplica√ß√£o [mangalivre](./mangalivre/) e uma do nosso [banco de dados](./mangalivre/database/) para centralizar os dados.

Todos os nossos arquivos de configura√ß√£o do `minikube` devem ficar na pasta [k8s](./k8s/) para organizar melhor o projeto.

Iremos criar um arquivo chamado `mangalivre-db-deployment.yaml` para o banco de dados com o seguinte conte√∫do:

```yml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: mangalivre-db
spec:
  replicas: 1
  selector:
    matchLabels:
      app: mangalivre-db
  template:
    metadata:
      labels:
        app: mangalivre-db
    spec:
      containers:
        - name: mangalivre-db
          image: mangalivre-db
          imagePullPolicy: Never
          env:
            - name: POSTGRES_USER
              value: "mangalivre"
            - name: POSTGRES_PASSWORD
              value: "mangalivre"
            - name: POSTGRES_DB
              value: "mangalivre"
          ports:
            - containerPort: 5432
          volumeMounts:
            - name: postgres-data
              mountPath: /var/lib/postgresql/data
      volumes:
        - name: postgres-data
          emptyDir: {}
---
apiVersion: v1
kind: Service
metadata:
  name: mangalivre-db
spec:
  ports:
    - port: 5432
      targetPort: 5432
  selector:
    app: mangalivre-db
```

Agora vamos criar um arquivo chamado `mangalivre-app-deployment.yaml` para a nossa aplica√ß√£o:

```yml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: mangalivre-app
spec:
  replicas: 2
  selector:
    matchLabels:
      app: mangalivre-app
  template:
    metadata:
      labels:
        app: mangalivre-app
    spec:
      containers:
        - name: mangalivre-app
          image: mangalivre-app:latest
          imagePullPolicy: Never
          ports:
            - containerPort: 3000
---
apiVersion: v1
kind: Service
metadata:
  name: mangalivre-app
spec:
  ports:
    - port: 3000
      targetPort: 3000
  selector:
    app: mangalivre-app
  type: NodePort
```

Com esses arquivos em m√£os, iremos usar os arquivos `Dockerfile` preparador anteriormente para iniciar nossa aplica√ß√£o. Caso tenha curiosidade em saber o conte√∫do destes arquivos, [clique aqui](./mangalivre/database/Dockerfile) para acessar o `Dockerfile` do Banco de Dados e [clique aqui](./mangalivre/Dockerfile) para acessar o `Dockerfile` da aplica√ß√£o.

Antes de iniciar, crie um arquivo `.env` dentro da pasta [mangalivre](./mangalivre/) com o seguinte conte√∫do:

```bash
DB_USER=mangalivre
DB_PASSWORD=mangalivre
DB_HOST=mangalivre-db
DB_PORT=5432
DB_NAME=mangalivre
```

Inicie o Minikube usando:

```bash
minikube start
```

Caso queira confirir se ele realmente iniciou corretamente, use:

```bash
minikube status
```

e caso queira reiniciar, use:

```bash
minikube stop
minikube start
```

Feito isso, agora vamos criar as imagens do nosso banco de dados e aplica√ß√£o usando o Docker do Minikube com os seguintes comandos:

```bash
eval $(minikube docker-env)
docker build -t mangalivre-db:latest ./mangalivre/database/
docker build -t mangalivre-app:latest ./mangalivre/
```

Use o kubectl para aplicar os arquivos de configura√ß√£o:

```bash
kubectl apply -f k8s/mangalivre-db-deployment.yaml
kubectl apply -f k8s/mangalivre-app-deployment.yaml
```

Verifique se os pods e servi√ßos foram criados corretamente:

```bash
kubectl get pods
kubectl get services
```

Caso algum `pod` tenha falhado, tente criar novamente usando:

```bash
kubectl delete pod -l app=mangalivre-app
kubectl apply -f k8s/mangalivre-app-deployment.yaml
```

Caso precise ver a estrutura e erros, use estes comandos

```bash
kubectl describe pod NOME_DO_POD
kubectl logs NOME_DO_POD
```

**Obs**: Lembre de adaptar para o `pod` de sua necessidade

Obtenha o URL do servi√ßo do aplicativo com o comando:

```bash
minikube service mangalivre-app
```

Isso abrir√° a aplica√ß√£o no navegador no navegador.

### Habilitando o mecanismo de auto-healing, garantindo que pods sejam recriados automaticamente em caso de falha

No Kubernetes, o mecanismo de auto-healing j√° est√° habilitado por padr√£o para os pods gerenciados por um Deployment. O controlador do Deployment monitora os pods e recria automaticamente qualquer pod que falhe ou seja exclu√≠do.

No entanto, voc√™ podemos garantir que o comportamento de auto-healing esteja configurado corretamente e ajustar algumas configura√ß√µes para melhorar a resili√™ncia.

Ao adicionar um `livenessProbe` Para melhorar o auto-healing, isso permite que o Kubernetes detecte se o cont√™iner est√° em um estado inconsistente (por exemplo, travado) e reinicie o pod automaticamente.

Iremos implementar isto em nosso `app` ao modificar o arquivo `mangalivre-app-deployment.yaml` no bloco `containers`:

```yml
containers:
  - name: mangalivre-app
    image: mangalivre-app:latest
    imagePullPolicy: Never
    ports:
      - containerPort: 3000
    livenessProbe:
      httpGet:
        path: /
        port: 3000
      initialDelaySeconds: 5
      periodSeconds: 10
```

**obs**:

- **httpGet**: Verifica se o endpoint / na porta 3000 est√° respondendo.
- **initialDelaySeconds**: Aguarda 5 segundos antes de iniciar as verifica√ß√µes.
- **periodSeconds**: Realiza a verifica√ß√£o a cada 10 segundos.

Podemos adicionar tamb√©m um `readinessProbe` para garantir que o pod s√≥ seja considerado pronto quando estiver realmente funcional. Isso evita que o Kubernetes envie tr√°fego para um pod que ainda est√° inicializando.

Iremos implementar isto em nosso `app` ao modificar o arquivo `mangalivre-app-deployment.yaml` no bloco `containers` novamente:

```yml
    readinessProbe:
      httpGet:
        path: /
        port: 3000
      initialDelaySeconds: 5
      periodSeconds: 10
```

Resultado final para o arquivo `mangalivre-db-deployment.yaml`:

```yml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: mangalivre-app
spec:
  replicas: 2
  selector:
    matchLabels:
      app: mangalivre-app
  template:
    metadata:
      labels:
        app: mangalivre-app
    spec:
      containers:
        - name: mangalivre-app
          image: mangalivre-app:latest
          imagePullPolicy: Never
          ports:
            - containerPort: 3000
          livenessProbe:
            httpGet:
              path: /
              port: 3000
            initialDelaySeconds: 5
            periodSeconds: 10

          readinessProbe:
            httpGet:
              path: /
              port: 3000
            initialDelaySeconds: 5
            periodSeconds: 10
---
apiVersion: v1
kind: Service
metadata:
  name: mangalivre-app
spec:
  ports:
    - port: 3000
      targetPort: 3000
  selector:
    app: mangalivre-app
  type: NodePort
```

Vamos aplicar as mudan√ßas usando

```bash
kubectl apply -f k8s/mangalivre-app-deployment.yaml
```

Agora vamos testar se realmente est√° funcionando.

Veja os pods usando

```bash
kubectl get pods
```

Seu resultado ser√° proximo deste

```bash
NAME                              READY   STATUS    RESTARTS   AGE
mangalivre-app-57885677cc-grxnz   1/1     Running   0          89s
mangalivre-app-57885677cc-ps6wn   1/1     Running   0          75s
mangalivre-db-f76d86c6d-h4qth     1/1     Running   0          15m
```

Agora ao deletar um dos pods do app, usando este comando:

```bash
kubectl delete pod mangalivre-app-57885677cc-grxnz
```

Ao listar novamente usando:

```bash
kubectl get pods
```

Resultado:

```bash
NAME                              READY   STATUS    RESTARTS   AGE
mangalivre-app-57885677cc-g9fd8   1/1     Running   0          33s
mangalivre-app-57885677cc-ps6wn   1/1     Running   0          3m28s
mangalivre-db-f76d86c6d-h4qth     1/1     Running   0          17m
```

Agora em caso de algo acontecer com nossa aplica√ß√£o, os pods ser√£o recriados.

### Configurando o Horizontal Pod Autoscaler (HPA) com base no uso de CPU

O HPA depende de m√©tricas para funcionar. No Minikube, precisamos habilitar o `Metrics Server`, que coleta m√©tricas de uso de CPU e mem√≥ria.

Para habilitar, use este comando:

```bash
minikube addons enable metrics-server
```

Verifique se o Metrics Server est√° funcionando usando:

```bash
kubectl get deployment -n kube-system metrics-server
```

Resultado esperado

```bash
mauriciobenjamin700@mauriciobenjamin700-Latitude-5300:~/projects/course/ufpi/minikube-test$ kubectl get deployment -n kube-system metrics-server
NAME             READY   UP-TO-DATE   AVAILABLE   AGE
metrics-server   0/1     1            0           6s
```

O HPA precisa de limites de CPU (resources.requests.cpu) configurados no Deployment para funcionar. Atualize o arquivo `mangalivre-app-deployment.yaml` para incluir os recursos:

```yml
spec:
  containers:
    - name: mangalivre-app
      image: mangalivre-app:latest
      imagePullPolicy: Never
      ports:
        - containerPort: 3000
      resources:
        requests:
          cpu: "200m" # 200 milicores (0.2 CPU)
        limits:
          cpu: "500m" # 500 milicores (0.5 CPU)
```

Ao final, seu arquivo `mangalivre-app-deployment.yaml` estar√° desta forma:

```yml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: mangalivre-app
spec:
  replicas: 2
  selector:
    matchLabels:
      app: mangalivre-app
  template:
    metadata:
      labels:
        app: mangalivre-app
    spec:
      containers:
        - name: mangalivre-app
          image: mangalivre-app:latest
          imagePullPolicy: Never
          ports:
            - containerPort: 3000
          livenessProbe:
            httpGet:
              path: /
              port: 3000
            initialDelaySeconds: 5
            periodSeconds: 10

          readinessProbe:
            httpGet:
              path: /
              port: 3000
            initialDelaySeconds: 5
            periodSeconds: 10
          resources:
            requests:
              cpu: "200m" # 200 milicores (0.2 CPU)
            limits:
              cpu: "500m" # 500 milicores (0.5 CPU)
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: mangalivre-app
spec:
  replicas: 2
  selector:
    matchLabels:
      app: mangalivre-app
  template:
    metadata:
      labels:
        app: mangalivre-app
    spec:
      containers:
        - name: mangalivre-app
          image: mangalivre-app:latest
          imagePullPolicy: Never
          ports:
            - containerPort: 3000
          livenessProbe:
            httpGet:
              path: /
              port: 3000
            initialDelaySeconds: 5
            periodSeconds: 10

          readinessProbe:
            httpGet:
              path: /
              port: 3000
            initialDelaySeconds: 5
            periodSeconds: 10
          resources:
            requests:
              cpu: "200m" # 200 milicores (0.2 CPU)
            limits:
              cpu: "500m" # 500 milicores (0.5 CPU)
---
apiVersion: v1
kind: Service
metadata:
  name: mangalivre-app
spec:
  ports:
    - port: 3000
      targetPort: 3000
  selector:
    app: mangalivre-app
  type: NodePort
```

Aplique as mudan√ßas usando:

```bash
kubectl apply -f k8s/mangalivre-app-deployment.yaml
```

Agora crie um arquivo chamado `mangalivre-app-hpa.yaml` para configurar o HPA com o seguinte conte√∫do:

```yml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: mangalivre-app-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: mangalivre-app
  minReplicas: 2
  maxReplicas: 5
  metrics:
    - type: Resource
      resource:
        name: cpu
        target:
          type: Utilization
          averageUtilization: 50 # Escala quando o uso de CPU ultrapassar 50%
```

Aplique o HPA usando:

```bash
kubectl apply -f k8s/mangalivre-app-hpa.yaml
```

Resultado esperado:

```bash
horizontalpodautoscaler.autoscaling/mangalivre-app-hpa created
```

Use o comando abaixo para verificar o status do HPA:

```bash
kubectl get hpa
```

Voc√™ ver√° algo como:

```bash
NAME                 REFERENCE                   TARGETS              MINPODS   MAXPODS   REPLICAS   AGE
mangalivre-app-hpa   Deployment/mangalivre-app   cpu: <unknown>/50%   2         5         2          58s
```

**Obs**:

- **TARGETS**: Mostra o uso atual de CPU em rela√ß√£o ao alvo configurado (50%).
- **REPLICAS**: Mostra o n√∫mero atual de r√©plicas.

Para testar o HPA, podemos gerar uma carga de CPU nos pods do mangalivre-app. Usaremos a ferramenta kubectl exec para executar um script que consome CPU.

Dado nossos pods que podemos escolher usando `kubectl get pods`:

```bash
NAME                              READY   STATUS    RESTARTS   AGE
mangalivre-app-57885677cc-g9fd8   1/1     Running   0          19m
mangalivre-app-57885677cc-ps6wn   1/1     Running   0          22m
mangalivre-db-f76d86c6d-h4qth     1/1     Running   0          37m
```

Vamos escolher `mangalivre-app-57885677cc-ps6wn` para o teste.

Execute o script a baixo em outro de seus terminais:

```bash
kubectl exec -it mangalivre-app-57885677cc-ps6wn -- /bin/sh -c "yes > /dev/null &"
```

Verifique novamente o HPA usando:

```bash
kubectl get hpa
```

E os pods usando:

```bash
kubectl top pods
```

Voc√™ ver√° novos pods sendo criados para lidar com a carga.

```bash
NAME                              CPU(cores)   MEMORY(bytes)   
mangalivre-app-57885677cc-g9fd8   1m           86Mi            
mangalivre-app-57885677cc-ps6wn   1000m        93Mi            
mangalivre-db-f76d86c6d-h4qth     1m           65Mi            
mauriciobenjamin700@mauriciobenjamin700-Latitude-5300:~/projects/course/ufpi/minikube-test$ 
```

Quando a carga de CPU diminuir, o HPA reduzir√° automaticamente o n√∫mero de r√©plicas para o valor m√≠nimo configurado (minReplicas).


‚úÖ Notebook B ‚Äì Prometheus
Objetivo
Implantar o Prometheus no Notebook B para monitorar remotamente o cluster Kubernetes rodando no Notebook A, e exibir m√©tricas em tempo real como:

N√∫mero de pods ativos

Uso de CPU

Estado dos pods (Running, Failed, Pending)

A√ß√µes disparadas pelo HPA

Pr√©-requisitos
A comunica√ß√£o de rede entre o Notebook B e o Minikube (Kubernetes) rodando no Notebook A deve estar funcionando (ping, curl etc.).

O Metrics Server deve estar habilitado no cluster Kubernetes (j√° feito no README).

Prometheus precisa ser configurado para acessar os endpoints do Kubernetes remotamente.

Passo 1: Instalar o Prometheus
No Notebook B, baixe e instale o Prometheus:
```bash
wget https://github.com/prometheus/prometheus/releases/download/v2.52.0/prometheus-2.52.0.linux-amd64.tar.gz
tar -xzf prometheus-2.52.0.linux-amd64.tar.gz
cd prometheus-2.52.0.linux-amd64
```

Passo 2: Configurar o Prometheus para acessar o cluster Kubernetes
Edite o arquivo prometheus.yml para incluir os endpoints do cluster Kubernetes. Exemplo de configura√ß√£o b√°sica:
```bash
global:
  scrape_interval: 15s

scrape_configs:
  - job_name: 'kubernetes-nodes'
    static_configs:
      - targets: ['<IP_DO_NOTEBOOK_A>:10255'] # ou porta exposta para cAdvisor

  - job_name: 'kubernetes-pods'
    static_configs:
      - targets: ['<IP_DO_NOTEBOOK_A>:3000']  # servi√ßo da aplica√ß√£o
```

Passo 3: Executar o Prometheus
No terminal do Notebook B:
```bash
./prometheus --config.file=prometheus.yml
```
Acesse no navegador:
üîó http://localhost:9090

Passo 4: Verificar M√©tricas em Tempo Real
No Prometheus Web UI:

1. Pesquise por m√©tricas como:
```bash
kube_pod_status_phase

container_cpu_usage_seconds_total

kube_deployment_status_replicas

kube_hpa_status_current_replicas
```

2. Voc√™ pode acompanhar:

O n√∫mero de r√©plicas antes/depois do HPA atuar

Quais pods est√£o ativos

Quando o HPA escala a aplica√ß√£o

‚úÖ O que o projeto exige
1. N√∫mero de pods ativos
üîç M√©trica esperada: kube_pod_status_phase

‚úÖ Como obter: essa m√©trica vem do kube-state-metrics, que n√£o est√° inclu√≠do por padr√£o no Prometheus puro.

‚ùó Solu√ß√£o: Voc√™ precisa instalar o kube-state-metrics no cluster Kubernetes no Notebook A.

2. Uso de CPU por pod/container
üîç M√©trica esperada: container_cpu_usage_seconds_total

‚úÖ Como obter: essa m√©trica vem do cAdvisor, que est√° embutido no kubelet.

‚ö†Ô∏è Aten√ß√£o: voc√™ precisa garantir que o endpoint /metrics/cadvisor do kubelet (geralmente na porta 10255) esteja acess√≠vel de fora do cluster (Notebook B).

‚ùó Alternativa: Rodar o node-exporter como DaemonSet no cluster e expor essa porta.

3. Estado dos pods (Running, Failed, Pending)
üîç M√©trica esperada: kube_pod_status_phase{phase="Running"} e similares.

‚úÖ Como obter: vem do kube-state-metrics.

4. A√ß√µes disparadas pelo HPA (n√∫mero de r√©plicas ao longo do tempo)
üîç M√©trica esperada:

kube_hpa_status_current_replicas

kube_hpa_status_desired_replicas

‚úÖ Como obter: tamb√©m vem do kube-state-metrics.

‚úÖ Conclus√£o
‚úîÔ∏è Para cumprir 100% dos requisitos, voc√™ precisa:
üì¶ Instalar o kube-state-metrics no seu cluster Minikube (Notebook A).

üìà Garantir que o Prometheus consiga acessar:

kubelet (para cAdvisor ou m√©tricas brutas de containers)

kube-state-metrics (para status dos pods, r√©plicas e HPA)

node-exporter (para m√©tricas da m√°quina f√≠sica, se quiser)

